{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330c12d0",
   "metadata": {},
   "source": [
    "# Book recommendation exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2743169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f7e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "df_ratings = pd.read_csv(\"BX-Book-Ratings.csv\", sep=\";\", quotechar='\"', escapechar=\"\\\\\", encoding=\"iso-8859-1\")\n",
    "df_users = pd.read_csv(\"BX-Users.csv\", sep=\";\", quotechar='\"', escapechar=\"\\\\\", encoding=\"iso-8859-1\")\n",
    "df_books = pd.read_csv(\"BX-Books.csv\", sep=\";\", quotechar='\"', escapechar=\"\\\\\", encoding=\"iso-8859-1\", usecols=[0, 1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c95ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278858 entries, 0 to 278857\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   User-ID   278858 non-null  int64  \n",
      " 1   Location  278858 non-null  object \n",
      " 2   Age       168096 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314c969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271379 entries, 0 to 271378\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   ISBN         271379 non-null  object\n",
      " 1   Book-Title   271379 non-null  object\n",
      " 2   Book-Author  271377 non-null  object\n",
      " 3   Publisher    271377 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6231b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d54b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed4593a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author                   Publisher  \n",
       "0    Mark P. O. Morford     Oxford University Press  \n",
       "1  Richard Bruce Wright       HarperFlamingo Canada  \n",
       "2          Carlo D'Este             HarperPerennial  \n",
       "3      Gina Bari Kolata        Farrar Straus Giroux  \n",
       "4       E. J. W. Barber  W. W. Norton &amp; Company  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f97345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn userID and Books ID to categorical label\n",
    "df_books[\"Book-ID2\"] = pd.Categorical(df_books[\"ISBN\"])\n",
    "df_books[\"Book-ID2\"] = df_books[\"Book-ID2\"].cat.codes\n",
    "\n",
    "df_users[\"User-ID2\"] = pd.Categorical(df_users[\"User-ID\"])\n",
    "df_users[\"User-ID2\"] = df_users[\"User-ID2\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae2848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the IDs in the ratings table to the new IDs\n",
    "index_user_map = df_users.set_index(\"User-ID\")[\"User-ID2\"]\n",
    "index_book_map = df_books.set_index(\"ISBN\")[\"Book-ID2\"]\n",
    "df_ratings[\"User-ID2\"] = df_ratings[\"User-ID\"].map(index_user_map)\n",
    "df_ratings[\"Book-ID2\"] = df_ratings[\"ISBN\"].map(index_book_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5443989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340556, 271379)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ratings[\"ISBN\"].unique()), len(df_books[\"ISBN\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc1c86",
   "metadata": {},
   "source": [
    "We can see that the provided database doesn't have enough \"IDs.\" I decided that I will **remove** the NaN entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d964fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_ratings.dropna()[[\"Book-Rating\", \"User-ID2\", \"Book-ID2\"]]\n",
    "dataset[\"Book-ID2\"] = dataset[\"Book-ID2\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a14447",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Book-Rating\"] = dataset[\"Book-Rating\"] - 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c1124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1031175 entries, 0 to 1149778\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   Book-Rating  1031175 non-null  float64\n",
      " 1   User-ID2     1031175 non-null  int32  \n",
      " 2   Book-ID2     1031175 non-null  int32  \n",
      "dtypes: float64(1), int32(2)\n",
      "memory usage: 23.6 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33f0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the data\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39fd26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def data_generator(data: pd.DataFrame, batch_size=128):\n",
    "    data = shuffle(data)\n",
    "    num_batches = int(np.ceil(len(data) // batch_size))\n",
    "    for i in range(num_batches):\n",
    "        # Grab a batch\n",
    "        end = min(len(data), (i + 1) * batch_size)\n",
    "        data_batch = data[i * batch_size: (i+1) * batch_size]\n",
    "        user_batch = data[\"User-ID2\"].to_numpy(dtype=np.int32)\n",
    "        book_batch = data[\"Book-ID2\"].to_numpy(dtype=np.int32)\n",
    "        rating_batch = data[\"Book-Rating\"].to_numpy(dtype=np.float32)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        user_batch = torch.from_numpy(user_batch)\n",
    "        book_batch = torch.from_numpy(book_batch)\n",
    "        rating_batch = torch.from_numpy(rating_batch)\n",
    "        \n",
    "        yield user_batch, book_batch, rating_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5da24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias for data generator\n",
    "train_generator = lambda: data_generator(df_train)\n",
    "test_generator = lambda: data_generator(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45cb2d",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "A simple ANN with 2 embeddings layers for the book and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62cadcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_books, num_embed, num_hiddens, drop_out):\n",
    "        super(BookRecommender, self).__init__()\n",
    "        \n",
    "        self.V1 = num_users\n",
    "        self.V2 = num_books\n",
    "        self.E = num_embed\n",
    "        self.H = num_hiddens\n",
    "        self.p = drop_out\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.user_embed = nn.Embedding(self.V1, self.E)\n",
    "        self.book_embed = nn.Embedding(self.V2, self.E)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.E, self.H),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.p),\n",
    "            nn.Linear(self.H, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, users, books):\n",
    "        # Embed the users and books\n",
    "        users_embed = self.user_embed(users)\n",
    "        books_embed = self.user_embed(books)\n",
    "        \n",
    "        # Concat the embedding vectors\n",
    "        out = torch.cat((users_embed, books_embed), dim=1)\n",
    "        \n",
    "        # Pass through dense layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "579fce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure(model: nn.Module, device: torch.device, lr, momentum, optim_medthod):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    if optim_medthod == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimize = optim.SGD(model.parameters(), lr, momentum)\n",
    "    \n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f39cf4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model:nn.Module, criterion, optimizer, device, train_loader, test_loader, num_epochs):\n",
    "    loss_his, test_his = np.zeros(num_epochs), np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for users, books, ratings in train_loader():\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move items to device\n",
    "            users, books, ratings = users.to(device), books.to(device), ratings.to(device).view(-1, 1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outs = model(users, books)\n",
    "            train_loss = criterion(outs, ratings)\n",
    "            train_losses.append(train_loss.item())\n",
    "            \n",
    "            # Update parameters\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_his[epoch] = np.mean(train_losses).item()\n",
    "            \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        test_losses = []\n",
    "        for users, books, ratings in test_loader():\n",
    "            # Move items to device\n",
    "            users, books, ratings = users.to(device), books.to(device), ratings.to(device)\n",
    "            #Forward pass\n",
    "            outs = model(users, books)\n",
    "            test_loss = criterion(outs, ratings)\n",
    "            test_losses.append(test_loss.item())\n",
    "        \n",
    "        test_his[epoch] = np.mean(test_losses).item()\n",
    "    \n",
    "    return loss_his, test_his"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb6a45",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a87704a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "optim_medthod = 'adam'\n",
    "momentum = 0.99\n",
    "num_epochs = 16\n",
    "num_hiddens = 256\n",
    "num_embed = 1\n",
    "drop_out = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3906f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BookRecommender(len(df_users), len(df_books), num_embed, num_hiddens, drop_out)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion, optimizer = configure(model, device, lr, momentum, optim_medthod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23682861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "402163cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m----> 3\u001b[0m loss_his, test_his \u001b[38;5;241m=\u001b[39m batch_gd(model, criterion, optimizer, device, train_generator, test_generator, \n\u001b[0;32m      4\u001b[0m                                 num_epochs) \n\u001b[0;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[29], line 20\u001b[0m, in \u001b[0;36mbatch_gd\u001b[1;34m(model, criterion, optimizer, device, train_loader, test_loader, num_epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m loss_his[epoch] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_losses)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start = perf_counter()\n",
    "loss_his, test_his = batch_gd(model, criterion, optimizer, device, train_generator, test_generator, \n",
    "                                num_epochs) \n",
    "end = perf_counter()\n",
    "f\"{end - start:.4f}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3b17c",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708320b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses overtime\n",
    "plt.tilte(\"Loss over time\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_his, label=\"train loss\")\n",
    "plt.plot(test_his, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some prediction\n",
    "test_data = test_generator()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, [(1,), (1,)], device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
